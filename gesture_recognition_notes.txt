一、数据集
	egogesture dataset, 20BN-Gester数据集
	Kaggle, ImageNet, UCSD-MHAD数据集


二、手工特征对手势的位置和变化建模
	1、手工特征算法：较强大的理论支撑+计算资源
		传统方法：手势检测与分割 -> 手势追踪 -> 特征提取 ->  手势分类及识别 -> 识别结果
				手势建模(图像处理+轨迹矫正+人工设计模型) -> 分类模型设计 -> 识别结果
	2、手势分割：颜色、深度学习方法
	    手势追踪：光流法、 KLT特征追踪
	    手势特征点：距离、角度、几何、Mesh几何特征
	    手势分类：模板匹配、动态时间调整DTW、状态图转移HMM，统计学习K近邻+SVM	


三、深度学习的手势识别
	1、mediapipe框架：手掌lazePalm、手部HandLandmark、手掌HandGesture
		手掌识别模型BlazePalm：用于识别手势的整体框架和方向SSD
		手部关键点模型HandLandmark：识别手部的关节点
		手掌识别模型HandGesture：用于识别到的手势关节点进行分类手势NMS
	2、目标任务：需要将手势与语义对应起来
		深度学习框架: pytorch, tensorflow, Paddle, Jittor
		mediapipe框架支持IOS,Android,Windows,Linux,Macos系统


四、手势识别系统的制作
	1、收集数据: 使用mediapipe框架手势特征点数据集, 手势图片训练网络
	2、使用LSTM时序网络进行手势识别(设计帧率num_frame控制 B,C,T,H,W)
	3、进行手势分类,模型融合输出分类hand gesture classification
	4、手势识别系统的部署与测试,开发软件测试tkinter界面


五、人体姿态估计
	1、人体模型构建: 
	人体由于是非刚性的结构物体，因此需要建立基于骨骼、轮廓或体积的模型
	2、人体姿态估计难点:
		(1).Articulation——关节点的位置、角度、大小、形状、姿态等预测难题
		(2).Occlusion——遮挡致使可检测关节点数量降低的难题
		(3).Scale variation——手势大小变化、手势姿态变化的难题(上下文信息,骨架连接解决)
	3、人体姿态获取:
		(1).数据采集:
			动作捕捉MoCap(Motion Capture)、基于视觉的方式(摄像头)、惯性传感器IMU
			根据捕捉场景的限制、惯性式精度需求：MoCap+IMU+视觉,使用反光贴来实现
		(2).设计流程:
			人体检测(Fast R-CNN, Yolo) -> 关键点定位(OpenPose, HRNet) -> 姿态跟踪
	4、姿态识别处理：
		(1).边缘计算设备：
			--> 模型优化(MobileNet, 网络剪枝，要求轻量化模型的部署) 
			--> 分布式计算(边缘计算设备的算力提升,多摄像头数据采集) 
			--> 网络边缘协同(实施设备边端计算，云端集中处理数据)
		(2).姿态估计方法：
			--> 自上而下方法：对多人进行检测，再估计各个部分，计算姿态(多)
			--> 自下而上方法：检测所有部分的关键点，再进行分组联合
			传统方法：图结构(Graph-based)和形变部件模型,通过人体行为学的约束以及连通性进行估计
					 高效率、但遮挡、几何模糊性鲁棒性低
					 使用深度学习则是通过提取大量数据的高度稳定的数据特征，实现对目标姿态的估计
					a.直接线性变换(DLT), 直接使用全局特征feature或者graphical model进行估计
					b.DPM特征, 基于HOG特征进行显示
			流程深度学习: 
					a.DeepPose模型通过整体精度的计算，第一级提取特侦点，第二级对节点裁剪图像提取特侦点，进行级数堆叠(自上而下)
					b.OpenPose模型通过对关键点的检测，再对关键点进行分类，进行级数堆叠(自下而上)
					c,DeepCut模型通过对图像进行分割，再对分割区域进行特征提取，进行级数堆叠(自下而上)
					d.PoseFlow模型通过对关键点的检测，再对关键点进行光流计算，进行级数堆叠(自下而上)
					e.PoseWarper模型通过对关键点的检测，再对关键点进行形变计算，进行级数堆叠(自下而上)
			单阶段深度学习：
					a.Associative Embedding网络
					b.Alpha-Pose网络
		(3).姿态估计类型：
			--> 2D姿态估计：检测关键点，再进行姿态估计
			--> 3D姿态估计：检测关键点，再进行三维姿态估计, RGB-D相机和双目相机采集数据
			目前三维姿态应用研究热点，应用较多，但仍有待进一步的研究
	5、数据集：
		来源：动捕设备采集，人工数据集标注，计算机图形学仿真
		(1).3D-dataset: DensePose, UP-3D, Human3.6m, HumanEva, Total Capture, MPI-INF-3DHP
		(2).2D-dataset: BBC Pose, COCO Keypoints, YouTube Pose(VGG), MPII, LSP, Leeds Sports Pose, MPI-Human-Pose


六、代码实现
	1、Data_Collection.py
		收集数据集——主要是持续时间为1.5秒的手势,帧数45,尺寸400*400,时间1.5,保存格式.avi
		收集到的数据保存在dataset文件夹下
		组织形式：
			dataset
				|____train
				|	|____video
				|	|____image
				|
				|____test
					|____video
					|____image
	2、实施策略：
		通过模型融合手段，结合视觉+特征点的方式进行识别，构建基础的backbone网络，然后再进行手势分类
		(1)、双网络融合输出：
			a. 特征点坐标LSTM是网络：对数据进行时序处理，输入网络的特征点坐标，LSTM网络进行时序学习，输出手势分类结果
			b. 特征点坐标PointNet++网络:输入手势特征点坐标，输出特征点坐标，再输入到LSTM网络进行时序学习，输出手势分类结果
		(2)、图像特征Transformer网络以及图像Temproal-Net光流预测检测：
			使用基础的transformer网络，对图像特征进行提取，再输入到LSTM网络进行时序学习，输出手势分类结果